{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:Red;\"> Importing the libaries </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:Green;\"> Sanitisation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping rows: (45585, 9)\n",
      "After dropping rows: (45550, 9)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45550 entries, 0 to 45584\n",
      "Data columns (total 9 columns):\n",
      "name                45550 non-null object\n",
      "category            45550 non-null object\n",
      "deadline            45550 non-null object\n",
      "launched            45550 non-null object\n",
      "backers             45550 non-null int64\n",
      "country             45550 non-null object\n",
      "usd_pledged_real    45550 non-null float64\n",
      "usd_goal_real       45550 non-null float64\n",
      "StateBin            45550 non-null int64\n",
      "dtypes: float64(2), int64(2), object(5)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "FullSetClean = pd.read_csv(\"data_edited3.csv\")\n",
    "\n",
    "#####\n",
    "\"\"\"\n",
    "Put Further Sanitation Code here.\n",
    "OR any sanitation code\n",
    "\"\"\"\n",
    "FullSetClean = FullSetClean.drop(columns = \"currency\")\n",
    "\n",
    "stateBin = []\n",
    "for row in FullSetClean[\"state\"]:\n",
    "    if row == \"successful\":\n",
    "        stateBin.append(1)\n",
    "    else:\n",
    "        stateBin.append(0)\n",
    "\n",
    "FullSetClean[\"StateBin\"] = stateBin\n",
    "FullSetClean = FullSetClean.drop(columns = \"state\")\n",
    "\n",
    "# Un-comment lines to see that it works\n",
    "\n",
    "CategoryList = FullSetClean[\"category\"].unique().tolist()\n",
    "print('Before dropping rows: {}' .format(FullSetClean.shape))\n",
    "\n",
    "index = 0\n",
    "\n",
    "for i in CategoryList:\n",
    "    Successful = 0\n",
    "    Failed = 0\n",
    "    tempDataFrame = FullSetClean[FullSetClean[\"category\"] == i]\n",
    "    for row in tempDataFrame[\"StateBin\"]:\n",
    "        if row == 1:\n",
    "            Successful += 1\n",
    "        else:\n",
    "            Failed += 1\n",
    "    Total = Failed + Successful\n",
    "    #print('The category {} has {} projects.' .format(name, Total))\n",
    "    if Total < 50:\n",
    "        FullSetClean.drop(index, axis=0, inplace=True)\n",
    "        #print('The category has been dropped.')\n",
    "    else:\n",
    "        pass\n",
    "    index += 1\n",
    "\n",
    "print('After dropping rows: {}' .format(FullSetClean.shape))\n",
    "\n",
    "FullSetClean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:Fuchsia;\"> The functions related to the words </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:Teal;\"> Letter Related Functions </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0.25\n",
      "0.6666666666666666\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def StartingChar(string : str): # discontinued as does not output a numerical number that could be used later.\n",
    "    return string[0]\n",
    "\n",
    "def Length(string : str):\n",
    "    return len(string)\n",
    "\n",
    "def NumberOfWords(string :  str):\n",
    "    output = 0\n",
    "    string = string.split()\n",
    "    for word in string:\n",
    "         if any(c.isalpha() for c in word): ##sees if there is a letter in the collection of chars\n",
    "                output += 1\n",
    "    return output\n",
    "\n",
    "def Capitilisation(string : str):\n",
    "    plus = 0\n",
    "    minus = 0\n",
    "    for char in string:\n",
    "        if char.islower():\n",
    "            plus +=1\n",
    "        elif char.isupper():\n",
    "            minus += 1\n",
    "    return (plus/(plus + minus))\n",
    "\n",
    "def Punctuation(string : str):\n",
    "    plus = 0\n",
    "    minus = 0\n",
    "    for char in string:\n",
    "        if char in \". , / ? ; : ‘ () !”\":\n",
    "            plus +=1\n",
    "        else:\n",
    "            minus += 1\n",
    "    return (plus/(plus + minus))\n",
    "\n",
    "def nonPunctuation(string:str):\n",
    "    plus = 0\n",
    "    minus = 0\n",
    "    for char in string:\n",
    "        if char in \"\\|£$%^&*-_+={}[]@~#<>¬\":\n",
    "            plus +=1\n",
    "        else:\n",
    "            minus += 1\n",
    "    return (plus/(plus + minus))\n",
    "\n",
    "def Vowels(string : str):\n",
    "    plus = 0\n",
    "    minus = 0\n",
    "    string = string.lower()\n",
    "    for char in string:\n",
    "        if char in \"aeiou\":\n",
    "            plus += 1\n",
    "        elif char.isalpha():\n",
    "            minus += 1\n",
    "    return (plus/(plus + minus))\n",
    "\n",
    "def Plositives(string : str):\n",
    "    plus = 0\n",
    "    minus = 0\n",
    "    string = string.lower()\n",
    "    for char in string:\n",
    "        if char in \"ptkbdg\":\n",
    "            plus += 1\n",
    "        elif char.isalpha():\n",
    "            minus += 1\n",
    "    return (plus/(plus + minus))\n",
    "\n",
    "def frictives(string : str):\n",
    "    plus = 0\n",
    "    minus = 0\n",
    "    string  = string.lower()\n",
    "    for char in string:\n",
    "        if char in \"fsvz\":\n",
    "            plus += 1\n",
    "        elif char.isalpha():\n",
    "            minus += 1\n",
    "    return (plus/(plus + minus))\n",
    "\n",
    "def alliteration(string : str):\n",
    "    output = 0\n",
    "    string = string.lower()\n",
    "    string = string.split()\n",
    "    previousLetter = \"\"\n",
    "    output = 0\n",
    "    for word in string:\n",
    "        if word[0] == previousLetter:\n",
    "                output += 1\n",
    "        else:\n",
    "            previousLetter = word[0]\n",
    "        \n",
    "    return output\n",
    "\n",
    "functionList = [\n",
    "                [Length , \"Word Length\"],\n",
    "                [NumberOfWords , \"Number Of Words\"],\n",
    "                [Capitilisation , \"Capitilisation\"],\n",
    "                [Punctuation , \"Punctuation\"],\n",
    "                [nonPunctuation , \"nonPunctuation\"],\n",
    "                [Vowels , \"Vowels\"],\n",
    "                [Plositives, \"Plositives\"],\n",
    "                [frictives,\"frictives\"],\n",
    "                [alliteration,\"alliteration\"]\n",
    "               ]\n",
    "    \n",
    "print(NumberOfWords(\"Test Test test a!\")) \n",
    "print (frictives(\"test test test\"))\n",
    "print (Capitilisation(\"TEst Test Test\"))\n",
    "print (alliteration(\"Fest Test test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At some point this will be changed to a genralised function.\n",
    "#base plan:\n",
    "#all the analytics function will take a string return a number (float or int 64 )\n",
    "\n",
    "#there will be an itterator high order function that takes the analytic function. \n",
    "#and the applies it to all of the titles and returns a list\n",
    "\n",
    "\n",
    "###The itterator high order\n",
    "\n",
    "def itterator(function,ColName,dataSet):\n",
    "    output = list()\n",
    "    for n , string in enumerate(dataSet[\"name\"]):\n",
    "        output.append(function(string))\n",
    "    dataSet[ColName] = output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function Length at 0x7fc7bec132f0>\n",
      "<function NumberOfWords at 0x7fc792481a60>\n",
      "<function Capitilisation at 0x7fc7924818c8>\n",
      "<function Punctuation at 0x7fc7924819d8>\n",
      "<function nonPunctuation at 0x7fc792481950>\n",
      "<function Vowels at 0x7fc792481b70>\n",
      "<function Plositives at 0x7fc792481c80>\n",
      "<function frictives at 0x7fc792481d08>\n",
      "<function alliteration at 0x7fc792481d90>\n",
      "done functions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for point in functionList:\n",
    "    itterator(point[0],point[1],FullSetClean)\n",
    "    print(point[0])\n",
    "\n",
    "print (\"done functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:Orange;\"> Time Related Functions </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def dateTimeitterator(dataSet):\n",
    "    Launchweekdays = []\n",
    "    Launchhours = []\n",
    "    elapsedDays= []\n",
    "    deadlineweekdays = []\n",
    "    draw = []\n",
    "    sraw = []\n",
    "    \n",
    "    for n , string in enumerate(dataSet[\"launched\"]):\n",
    "        date , time = string.split(\" \")\n",
    "        day , month ,year = date.split(\"/\")\n",
    "        hour, mineut = time.split(\":\")\n",
    "        raw = datetime.date(int(year), int(month), int(day))\n",
    "\n",
    "        \n",
    "        Launchweekdays.append(int(raw.weekday()))\n",
    "        Launchhours.append(int(hour))\n",
    "        sraw.append(raw)\n",
    "        \n",
    "    for n , string in enumerate(dataSet[\"deadline\"]):\n",
    "        \n",
    "        day , month ,year = string.split(\"/\")\n",
    "        hour, mineut = time.split(\":\")\n",
    "        raw = datetime.date(int(year), int(month), int(day))\n",
    "        deadlineweekdays.append(raw.weekday())\n",
    "        draw.append(raw)\n",
    "        \n",
    "\n",
    "    elapsedDays = [(a - b).days for a, b in zip(sraw, draw)]\n",
    "    dataSet[\"LaunchWeekday\"] = Launchweekdays\n",
    "    dataSet[\"LaunchHour\"] =  Launchhours\n",
    "    dataSet[\"elapsedDay\"] = elapsedDays\n",
    "    dataSet[\"deadlineWeekday\"] = deadlineweekdays\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done Timeritterato\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dateTimeitterator(FullSetClean)\n",
    "print (\"done Timeritterato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:salmon;\"> Data Base Splitting (to be added data base correction) + Dataset Balancing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data base splitting done bellow \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train,other = train_test_split(FullSetClean, test_size=0.6,random_state=0);\n",
    "\n",
    "validation , test = train_test_split(other, test_size=0.5,random_state=0);\n",
    "\n",
    "train.head()\n",
    "\n",
    "# FullSetClean.head()\n",
    "# FullSetClean.info(verbose = True)\n",
    "\n",
    "# BALANCES THE TRAINING DATASET:\n",
    "\n",
    "total = len(train)\n",
    "nb_pos = train['StateBin'].sum()\n",
    "nb_neg = total - nb_pos\n",
    "\n",
    "success_pos = train.loc[train['StateBin'] == 1]\n",
    "success_neg = train.loc[train['StateBin'] == 0].sample(nb_pos)\n",
    "\n",
    "resampled_train = pd.concat((success_pos, success_neg))\n",
    "\n",
    "# CHECKS THAT RESAMPLING HAS BEEN SUCCESSFUL:\n",
    "\n",
    "# total = len(resampled_train)\n",
    "# nb_pos = resampled_train['StateBin'].sum()\n",
    "# nb_neg = total - nb_pos\n",
    "\n",
    "# print('Successful: {}' .format(nb_pos))\n",
    "# print('Failed: {}' .format(nb_neg))\n",
    "\n",
    "# BALANCES THE VALIDATION DATASET:\n",
    "\n",
    "total = len(validation)\n",
    "nb_pos = validation['StateBin'].sum()\n",
    "nb_neg = total - nb_pos\n",
    "\n",
    "success_pos = validation.loc[validation['StateBin'] == 1]\n",
    "success_neg = validation.loc[validation['StateBin'] == 0].sample(nb_pos)\n",
    "\n",
    "resampled_validation = pd.concat((success_pos, success_neg))\n",
    "\n",
    "# CHECKS THAT RESAMPLING HAS BEEN SUCCESSFUL:\n",
    "\n",
    "# total = len(resampled_validation)\n",
    "# nb_pos = resampled_validation['StateBin'].sum()\n",
    "# nb_neg = total - nb_pos\n",
    "\n",
    "# print('Successful: {}' .format(nb_pos))\n",
    "# print('Failed: {}' .format(nb_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:Purple;\"><i> Now for the word proccessing </i></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ghgh', 'ghgh', 'fdkfkf', 'g']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def sanitiser(title : str) -> list: #takes a string splits into words , makes lower case and removes punctuation\n",
    "    words = title.split()\n",
    "    output = []\n",
    "    for word in words:\n",
    "       output.append(re.sub(r'\\W+', '', word).lower())\n",
    "    return output\n",
    "\n",
    "def WordFinder(dataSet,cutoff : int) -> dict and list: #so takes in the data set , a cut off an renturns a list of all words above the cutoff and their percentage chance of succsess\n",
    "    LargeWordDictionary = {} #The dict for all of the words \n",
    "    \n",
    "    for n , title in enumerate(dataSet[\"name\"]): #goes through the big old list\n",
    "        temp = sanitiser(title) #sanitises the function\n",
    "        for word in temp: #basically sees if the word is already in the large list of words if it is then it adds its location in the data base to the end of the dict entry\n",
    "            try:\n",
    "                LargeWordDictionary[word].append(n)\n",
    "            except KeyError:\n",
    "                LargeWordDictionary[word] = [n]\n",
    "                \n",
    "    SmallWordDictionary = {} #small output dictionary\n",
    "    StateBin = dataSet[\"StateBin\"].tolist() #transfers database to list due to pandas related issues\n",
    "    for word in LargeWordDictionary: # goes through large dictionary , counts number of instances of each word appearing , and then uses the pointers to find if they were success \n",
    "        Suc = 0\n",
    "        for pointer in LargeWordDictionary[word]:\n",
    "            Suc += StateBin[int(pointer)]\n",
    "        length = len(LargeWordDictionary[word])\n",
    "        if length >= cutoff:\n",
    "            SmallWordDictionary[word] = [length , Suc/length]\n",
    "    print(len(SmallWordDictionary))\n",
    "    \n",
    "    WordLevels = [[a,[]] for a in range(10)]\n",
    "    for word in SmallWordDictionary:\n",
    "        WordLevels[int(SmallWordDictionary[word][1]*10)][1].append(word)\n",
    "    \n",
    "    return SmallWordDictionary , WordLevels\n",
    "        \n",
    "    #return LargeWordDictionary\n",
    "\n",
    "\n",
    "def WordScore(title : str,AssementDictionary : dict ,split : int) ->list:\n",
    "    title = sanitiser(title)\n",
    "    output = [0 for i in range(split)]\n",
    "    unique = 0\n",
    "    for word in title:\n",
    "        try:\n",
    "            temp = AssementDictionary[word][1]\n",
    "            for i in range(split):\n",
    "                if temp > 1 *((i+1)/split):\n",
    "                    pass\n",
    "                else:\n",
    "                    output[i] += 1\n",
    "                    break\n",
    "        except KeyError:\n",
    "            unique += 1\n",
    "    return output , unique\n",
    "\n",
    "\n",
    "def wordItterator(dataset , split): #### UNUSED FUNCTION AT THE MOMENT\n",
    "    output = []\n",
    "    for n , title in enumerate(dataSet[\"name\"]):\n",
    "        output.append(WordScore(title,dataset,assmentDict,split))\n",
    "    output = np.transpose(output)\n",
    "    for n , row in enumerate(output):\n",
    "        dataset[str(n)] = row\n",
    "        \n",
    "        \n",
    "    \n",
    "def wordWorst(title : str , AssementDict : dict):\n",
    "    title = sanitiser(title)\n",
    "    unique = 0\n",
    "    for word in title:\n",
    "        try:\n",
    "            temp = AssementDict[word][1]\n",
    "            if temp > maximum:\n",
    "                maximum = temp\n",
    "            elif temp < minimum:\n",
    "                minimum = temp\n",
    "        except KeyError:\n",
    "            unique += 1\n",
    "        except NameError:\n",
    "            maximum , minimum = temp , temp\n",
    "    \n",
    "    try:\n",
    "        return maximum , minimum , unique\n",
    "    except NameError:\n",
    "        return 0.5 , 0.5 , unique #There may be a better way of dealig with this but this just an easy way to deal with it.\n",
    "    \n",
    "    \n",
    "def wordWorstItterator(dataSet,AssmentDict):\n",
    "    maximum = []\n",
    "    minimum = []\n",
    "    unique = []\n",
    "    for n , title in enumerate(dataSet[\"name\"]):\n",
    "        temp = wordWorst(title ,AssmentDict )\n",
    "        maximum.append(temp[0])\n",
    "        minimum.append(temp[1])\n",
    "        unique.append(temp[2])\n",
    "    dataSet[\"maximum\"] = maximum\n",
    "    dataSet[\"minimum\"] = minimum\n",
    "    dataSet[\"unique\"] = unique\n",
    "    \n",
    "sanitiser(\"ghgh ghgh!!!!  FDKFKF  g\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233\n",
      "[[0, ['online']], [1, ['app', 'clothing', 'fashion', 'social']], [2, ['brand', 'my', 'fitness', 'apparel', 'community']], [3, ['mobile', 'life', 'handmade', 'en', 'de', 'live', 'food', 'video', 'books', 'movie', 'journey', 'organic', 'bar', 'me', 'cafe', 'can', 'dog', 'free', 'just', 'or']], [4, ['your', 'for', 'to', 'family', 'with', 'art', 'and', 'water', 'project', 'gaming', 'experience', 'be', 'man', 'production', 'people', 'not', 'design', 'custom', 'help', 'get', 'on', 'it', 'series', 'show', 'system', 'original', 'el', 'luxury', 'kids', 'back', 'more', 'la', 'fund', 'we', 'our', 'way', 'coffee', 'world', 'magazine', 'photography', 'american', 'up', 'company', 'launch', 'making', 'power', 'natural', 'i', 'support', 'save', 'what', 'dream', 'through']], [5, ['a', 'from', 'co', '', 'no', 'into', 'fun', 'card', 'game', 'the', 'all', 'in', 'an', 'new', 'is', 'of', 'novel', 'box', 'better', 'out', 'house', 'are', 'you', 'earth', 'at', 'feature', 'party', 'love', 'one', 'story', '4', 'book', 'women', 'home', 'travel', 'table', 'red', 'studio', 'music', 'modern', 'lost', '3d', 'affordable', 'light', 'tour', 'time', 'this', 'made', 'great', 'next', 'cat', 'us', 'childrens', 'horror', 'inspired', 'future', 'its', 'high', 'hand', 'best', 'black', 'night', 'war', 'road', 'go', 'artist']], [6, ['kit', 'leather', 'smart', 'last', 'cards', '2', 'season', 'short', 'film', 'two', 'by', 'full', 'action', 'ep', 'record', 'dark', 'board', 'tea', '3', 'little', 'documentary', 'make', '100', 'festival', 'band', 'big', '1', 'games', 'adventure', 'watches', 'first', 'bag', 'space', 'most', 'city', 'like', 'play', 'adventures', 'dance', 'that', 'ultimate', 'comics', 'portable', 'hard', 'print', 'watch', 'cd', 'good', 'day', 'presents', 'calendar', 'graphic']], [7, ['set', 'debut', 'album', 'fantasy', '2017', 'playing', 'issue', 'comic', 'rpg', 'pen', 'second', 'enamel', 'pin', 'pins', 'collection', 'worlds', 'vinyl', 'wallet', 'anthology', '20', 'tabletop', '2018', 'limited', 'backpack', 'about', 'volume', 'gold', 'deck', 'kickstarter']], [8, ['dice', 'edition', 'miniatures']], [9, []]]\n",
      "([0, 0, 0, 1, 0, 0, 0, 0, 1, 0], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>deadline</th>\n",
       "      <th>launched</th>\n",
       "      <th>backers</th>\n",
       "      <th>country</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <th>usd_goal_real</th>\n",
       "      <th>StateBin</th>\n",
       "      <th>Word Length</th>\n",
       "      <th>...</th>\n",
       "      <th>Plositives</th>\n",
       "      <th>frictives</th>\n",
       "      <th>alliteration</th>\n",
       "      <th>LaunchWeekday</th>\n",
       "      <th>LaunchHour</th>\n",
       "      <th>elapsedDay</th>\n",
       "      <th>deadlineWeekday</th>\n",
       "      <th>maximum</th>\n",
       "      <th>minimum</th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>A Winter Cocktail Kit from Woodward Extract Co.</td>\n",
       "      <td>Drinks</td>\n",
       "      <td>15/12/2017</td>\n",
       "      <td>18/11/2017 03:59</td>\n",
       "      <td>198</td>\n",
       "      <td>US</td>\n",
       "      <td>11194.00</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-27</td>\n",
       "      <td>4</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.561383</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>Ideka- Ultra-Slim Premium Leather Wallets</td>\n",
       "      <td>Product Design</td>\n",
       "      <td>05/05/2017</td>\n",
       "      <td>05/04/2017 00:18</td>\n",
       "      <td>357</td>\n",
       "      <td>US</td>\n",
       "      <td>8799.00</td>\n",
       "      <td>1800.00</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23774</th>\n",
       "      <td>ORII - Your Voice Powered Smart Ring</td>\n",
       "      <td>Wearables</td>\n",
       "      <td>17/08/2017</td>\n",
       "      <td>18/07/2017 13:32</td>\n",
       "      <td>2082</td>\n",
       "      <td>US</td>\n",
       "      <td>333619.00</td>\n",
       "      <td>30000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.420479</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292</th>\n",
       "      <td>No Brains for Dinner</td>\n",
       "      <td>Plays</td>\n",
       "      <td>04/01/2017</td>\n",
       "      <td>05/12/2016 04:14</td>\n",
       "      <td>52</td>\n",
       "      <td>US</td>\n",
       "      <td>1876.00</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.477111</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19919</th>\n",
       "      <td>Classic Dice Set</td>\n",
       "      <td>Tabletop Games</td>\n",
       "      <td>20/04/2017</td>\n",
       "      <td>30/03/2017 22:38</td>\n",
       "      <td>35</td>\n",
       "      <td>ES</td>\n",
       "      <td>2673.44</td>\n",
       "      <td>2139.61</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>-21</td>\n",
       "      <td>3</td>\n",
       "      <td>0.872093</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name        category  \\\n",
       "2269   A Winter Cocktail Kit from Woodward Extract Co.          Drinks   \n",
       "1372         Ideka- Ultra-Slim Premium Leather Wallets  Product Design   \n",
       "23774             ORII - Your Voice Powered Smart Ring       Wearables   \n",
       "5292                              No Brains for Dinner           Plays   \n",
       "19919                                 Classic Dice Set  Tabletop Games   \n",
       "\n",
       "         deadline          launched  backers country  usd_pledged_real  \\\n",
       "2269   15/12/2017  18/11/2017 03:59      198      US          11194.00   \n",
       "1372   05/05/2017  05/04/2017 00:18      357      US           8799.00   \n",
       "23774  17/08/2017  18/07/2017 13:32     2082      US         333619.00   \n",
       "5292   04/01/2017  05/12/2016 04:14       52      US           1876.00   \n",
       "19919  20/04/2017  30/03/2017 22:38       35      ES           2673.44   \n",
       "\n",
       "       usd_goal_real  StateBin  Word Length  ...  Plositives  frictives  \\\n",
       "2269         5000.00         1           47  ...    0.230769   0.025641   \n",
       "1372         1800.00         1           41  ...    0.171429   0.057143   \n",
       "23774       30000.00         1           36  ...    0.137931   0.068966   \n",
       "5292         1500.00         1           20  ...    0.117647   0.117647   \n",
       "19919        2139.61         1           16  ...    0.142857   0.214286   \n",
       "\n",
       "       alliteration  LaunchWeekday  LaunchHour  elapsedDay  deadlineWeekday  \\\n",
       "2269              0              5           3         -27                4   \n",
       "1372              0              2           0         -30                4   \n",
       "23774             0              1          13         -30                3   \n",
       "5292              0              0           4         -30                2   \n",
       "19919             0              3          22         -21                3   \n",
       "\n",
       "        maximum   minimum  unique  \n",
       "2269   0.611111  0.561383       4  \n",
       "1372   0.642857  0.642857       4  \n",
       "23774  0.606742  0.420479       4  \n",
       "5292   0.520548  0.477111       2  \n",
       "19919  0.872093  0.758065       1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainAll,TrainClasses = WordFinder(resampled_train,40)\n",
    "\n",
    "wordWorstItterator(resampled_train,TrainAll)\n",
    "\n",
    "print(TrainClasses)\n",
    "\n",
    "print (WordScore(\"miniatures blank food\",TrainAll,10))\n",
    "\n",
    "resampled_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:Navy;\"> Machine Learning Code Taken From Tutorial </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def select_column_to_add(X_train, y_train, X_val, y_val, columns_in_model, columns_to_test):\n",
    "    \n",
    "    column_best = None\n",
    "    columns_in_model = list(columns_in_model)\n",
    "    \n",
    "    if len(columns_in_model) == 0:\n",
    "        acc_best = 0\n",
    "    elif len(columns_in_model) == 1:\n",
    "        mod = LogisticRegression(C=1e9).fit(X_train[columns_in_model].values.reshape(-1, 1), y_train)\n",
    "        acc_best = accuracy_score(y_val, mod.predict(X_val[columns_in_model].values.reshape(-1, 1)))\n",
    "    else:\n",
    "        mod = LogisticRegression(C=1e9).fit(X_train[columns_in_model], y_train)\n",
    "        acc_best = accuracy_score(y_val, mod.predict(X_val[columns_in_model]))\n",
    "\n",
    "    \n",
    "    for column in columns_to_test:\n",
    "        mod = LogisticRegression(C=1e9).fit(X_train[columns_in_model+[column]], y_train)\n",
    "        y_pred = mod.predict(X_val[columns_in_model+[column]])\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        \n",
    "        if acc - acc_best >= 0.005:  # one of our stopping criteria\n",
    "            acc_best = acc\n",
    "            column_best = column\n",
    "        \n",
    "    if column_best is not None:  # the other stopping criteria\n",
    "        print('Adding {} to the model'.format(column_best))\n",
    "        print('The new best validation accuracy is {}'.format(acc_best))\n",
    "        columns_in_model_updated = columns_in_model + [column_best]\n",
    "    else:\n",
    "        print('Did not add anything to the model')\n",
    "        columns_in_model_updated = columns_in_model\n",
    "    \n",
    "    return columns_in_model_updated, acc_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18234 entries, 27204 to 2732\n",
      "Data columns (total 13 columns):\n",
      "Word Length        18234 non-null int64\n",
      "Number Of Words    18234 non-null int64\n",
      "Capitilisation     18234 non-null float64\n",
      "Punctuation        18234 non-null float64\n",
      "nonPunctuation     18234 non-null float64\n",
      "Vowels             18234 non-null float64\n",
      "Plositives         18234 non-null float64\n",
      "frictives          18234 non-null float64\n",
      "alliteration       18234 non-null int64\n",
      "LaunchWeekday      18234 non-null int64\n",
      "LaunchHour         18234 non-null int64\n",
      "elapsedDay         18234 non-null int64\n",
      "deadlineWeekday    18234 non-null int64\n",
      "dtypes: float64(6), int64(7)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "dropstuff = [\"StateBin\",\"name\",\"category\",\"deadline\",\"launched\",\"country\",\"usd_goal_real\",\"usd_pledged_real\",\"backers\"]\n",
    "\n",
    "Ytrain = train[[\"StateBin\"]]  #what you want to predict\n",
    "Xtrain = train.drop(columns = dropstuff) #all the other data\n",
    "Yval = validation[[\"StateBin\"]]  #what you want to predict\n",
    "Xval = validation.drop(columns = dropstuff) #all the other data\n",
    "\n",
    "Xtrain.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding frictives to the model\n",
      "The new best validation accuracy is 0.5869835466179159\n",
      "Did not add anything to the model\n",
      "Did not add anything to the model\n",
      "Did not add anything to the model\n"
     ]
    }
   ],
   "source": [
    "columns_to_test = set(Xtrain)\n",
    "full_list = set(Xtrain)\n",
    "\n",
    "columns_in_model = list();\n",
    "\n",
    "for i in range(4):\n",
    "    columns_in_model , acc = select_column_to_add(Xtrain,Ytrain,Xval,Yval,columns_in_model,columns_to_test)    \n",
    "    columns_to_test = full_list.difference(columns_in_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:DodgerBlue;\"> Now For the Graphs </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentageAtIntervalFloat(dataSet ,varible : str,splits : int) -> list :\n",
    "    #create the search thing\n",
    "    minimum = dataSet[varible].min()\n",
    "    maximum = dataSet[varible].max()\n",
    "    print(minimum , maximum)\n",
    "    difference = maximum - minimum\n",
    "    space = difference / splits\n",
    "    output = [[a,[0,0]] for a in np.arange(minimum,maximum,space)]\n",
    "    testLevels = [a for a in np.arange(minimum,maximum,space)]\n",
    "    Values = dataSet[varible].tolist()\n",
    "    successes = dataSet[\"StateBin\"].tolist()\n",
    "    \n",
    "    for Value , success in zip(Values,successes):\n",
    "        for n , level in enumerate(testLevels):\n",
    "            if Value <= level:\n",
    "                if  success == 1:\n",
    "                    output[n][1][1] += 1\n",
    "                else:\n",
    "                    output[n][1][0] += 1\n",
    "                break\n",
    "    \n",
    "    percentOutput = []\n",
    "    for level in output:\n",
    "        if level[1][1] == 0:\n",
    "            percentOutput.append(0)\n",
    "        else:\n",
    "            percentOutput.append(level[1][1]/(level[1][1]+level[1][0]))\n",
    "    return percentOutput\n",
    "\n",
    "def percentageAtIntervalInt(dataSet ,varible : str) -> list : ###Recode so that it works with intergers\n",
    "    #create the search thing\n",
    "    minimum = dataSet[varible].min()\n",
    "    maximum = dataSet[varible].max()\n",
    "    difference = maximum - minimum\n",
    "    output = [[a,[0,0]] for a in np.arange(minimum,maximum)]\n",
    "    testLevels = [a for a in np.arange(minimum,maximum)]\n",
    "    Values = dataSet[varible].tolist()\n",
    "    successes = dataSet[\"StateBin\"].tolist()\n",
    "    \n",
    "    for Value , success in zip(Values,successes):\n",
    "        for n , level in enumerate(testLevels):\n",
    "            if Value <= level:\n",
    "                if  success == 1:\n",
    "                    output[n][1][1] += 1\n",
    "                else:\n",
    "                    output[n][1][0] += 1\n",
    "                break\n",
    "    \n",
    "    percentOutput = []\n",
    "    for level in output:\n",
    "        if level[1][1] == 0:\n",
    "            percentOutput.append(0)\n",
    "        else:\n",
    "            percentOutput.append(level[1][1]/(level[1][1]+level[1][0]))\n",
    "    return percentOutput\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Length\n",
      "1 60\n",
      "Number Of Words\n",
      "1 16\n",
      "Capitilisation\n",
      "0.0 1.0\n",
      "Punctuation\n",
      "0.0 0.5666666666666667\n",
      "nonPunctuation\n",
      "0.0 0.46153846153846156\n",
      "Vowels\n",
      "0.0 1.0\n",
      "Plositives\n",
      "0.0 1.0\n",
      "frictives\n",
      "0.0 0.6666666666666666\n",
      "alliteration\n",
      "0 6\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test[\"Vowels\"].max()\n",
    "for n , Fun in enumerate(functionList):\n",
    "\n",
    "    print(Fun[1])\n",
    "    LookList = percentageAtIntervalFloat(FullSetClean , Fun[1],20)\n",
    "    plt.subplot(3,3,n + 1)\n",
    "    plt.plot(LookList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
